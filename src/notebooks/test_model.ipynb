{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:51:21.034487Z",
     "start_time": "2023-11-23T08:51:17.743767Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../detr')\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from scipy import ndimage\n",
    "import bisect\n",
    "from src.eval import infer_visualize\n",
    "from src.main import get_model\n",
    "import json\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from PIL import Image, ImageOps\n",
    "import warnings\n",
    "import torchvision.models as tmd\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.models._utils import IntermediateLayerGetter\n",
    "from thop import profile\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--data_root_dir',\n",
    "                        # required=True,\n",
    "                        help=\"Root data directory for images and labels\")\n",
    "    parser.add_argument('--config_file',\n",
    "                        # required=True,\n",
    "                        help=\"Filepath to the config containing the args\")\n",
    "    parser.add_argument('--backbone',\n",
    "                        default='resnet18',\n",
    "                        help=\"Backbone for the model\")\n",
    "    parser.add_argument(\n",
    "        '--data_type',\n",
    "        choices=['detection', 'structure'],\n",
    "        default='structure',\n",
    "        help=\"toggle between structure recognition and table detection\")\n",
    "    parser.add_argument('--model_load_path', help=\"The path to trained model\")\n",
    "    parser.add_argument('--load_weights_only', action='store_true')\n",
    "    parser.add_argument('--model_save_dir', help=\"The output directory for saving model params and checkpoints\")\n",
    "    parser.add_argument('--metrics_save_filepath',\n",
    "                        help='Filepath to save grits outputs',\n",
    "                        default='')\n",
    "    parser.add_argument('--debug_save_dir',\n",
    "                        help='Filepath to save visualizations',\n",
    "                        default='debug')\n",
    "    parser.add_argument('--table_words_dir',\n",
    "                        help=\"Folder containg the bboxes of table words\")\n",
    "    parser.add_argument('--mode',\n",
    "                        choices=['train', 'eval'],\n",
    "                        default='train',\n",
    "                        help=\"Modes: training (train) and evaluation (eval)\")\n",
    "    parser.add_argument('--debug', action='store_true')\n",
    "    parser.add_argument('--device')\n",
    "    parser.add_argument('--lr', type=float)\n",
    "    parser.add_argument('--lr_drop', type=int)\n",
    "    parser.add_argument('--lr_gamma', type=float)\n",
    "    parser.add_argument('--epochs', type=int)\n",
    "    parser.add_argument('--checkpoint_freq', default=1, type=int)\n",
    "    parser.add_argument('--batch_size', type=int)\n",
    "    parser.add_argument('--num_workers', type=int)\n",
    "    parser.add_argument('--train_max_size', type=int)\n",
    "    parser.add_argument('--val_max_size', type=int)\n",
    "    parser.add_argument('--test_max_size', type=int)\n",
    "    parser.add_argument('--eval_pool_size', type=int, default=1)\n",
    "    parser.add_argument('--eval_step', type=int, default=1)\n",
    "    \n",
    "    parser.add_argument('--overlap', action='store_true')\n",
    "    parser.add_argument(\"--overlap_loss_coef\", type=int, default=1)\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:51:21.034821Z",
     "start_time": "2023-11-23T08:51:21.033445Z"
    }
   },
   "id": "d06cb3ca43291fa1"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "image_folder = '/home/suqi/dataset/screenshot'\n",
    "\n",
    "# 随机选择部分样本进行测试\n",
    "k = 500\n",
    "np.random.seed(0)\n",
    "# test_list = sorted([name for name in os.listdir(image_folder) if 'COL' in name])\n",
    "test_list = sorted([name for name in os.listdir(image_folder)])\n",
    "# np.random.shuffle(test_list)\n",
    "# test_list = test_list[:k]\n",
    "img_paths = [os.path.join(image_folder, name) for name in test_list]\n",
    "\n",
    "# img_names = ['_'.join(name.split('_')[:-1]) + '.jpg' for name in os.listdir('/home/suqi/dataset/temp/visualize')]\n",
    "# img_paths = [os.path.join(image_folder, name) for name in list(set(img_names))]\n",
    "print(len(img_paths))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:51:21.136438Z",
     "start_time": "2023-11-23T08:51:21.033746Z"
    }
   },
   "id": "33a96ca9dc3820ea"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "samples = []\n",
    "img_paths_filter = []\n",
    "errors = 0\n",
    "for path in img_paths:\n",
    "    try:\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        w, h = image.size\n",
    "        padding_size = int(min(w, h) * 0.2)\n",
    "        image = ImageOps.expand(image, border=padding_size, fill='white')\n",
    "        samples.append(image)\n",
    "        img_paths_filter.append(path)\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        print(f\"Exception when load image {path}\")\n",
    "img_paths = img_paths_filter\n",
    "print(errors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:51:21.573499Z",
     "start_time": "2023-11-23T08:51:21.136294Z"
    }
   },
   "id": "4ace3443e2d19a59"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from checkpoint\n",
      "load model parameters successfully!\n"
     ]
    }
   ],
   "source": [
    "args = get_args()\n",
    "args.config_file = \"../structure_config.json\"\n",
    "args.data_type = None\n",
    "args.model_load_path = \"/home/suqi/model/TATR/finetune/train_finetune_resnet34/model_best.pth\"\n",
    "args.backbone = \"resnet34\"\n",
    "args.debug_save_dir = \"/home/suqi/dataset/temp/visualize_html_image_resnet34/\"\n",
    "os.makedirs(args.debug_save_dir, exist_ok=True)\n",
    "args.device = \"cuda:3\"\n",
    "\n",
    "cmd_args = args.__dict__\n",
    "config_args = json.load(open(cmd_args['config_file'], 'rb'))\n",
    "for key, value in cmd_args.items():\n",
    "    if not key in config_args or not value is None:\n",
    "        config_args[key] = value\n",
    "# config_args.update(cmd_args)\n",
    "args = type('Args', (object,), config_args)\n",
    "\n",
    "# define and load model\n",
    "device = torch.device(args.device)\n",
    "model, _, _ = get_model(args, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:51:23.291880Z",
     "start_time": "2023-11-23T08:51:21.575708Z"
    }
   },
   "id": "b1b0f30ab60c4ce7"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring: : 31it [02:26,  4.73s/it]\n"
     ]
    }
   ],
   "source": [
    "# 约3.00s/it\n",
    "infer_visualize(model, samples, device, img_paths, args.debug_save_dir, True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:53:57.540368Z",
     "start_time": "2023-11-23T08:51:26.974682Z"
    }
   },
   "id": "263cad958f037683"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T08:53:58.120714Z",
     "start_time": "2023-11-23T08:53:57.538780Z"
    }
   },
   "id": "a6b2c5ef0b8a7d23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 分开测试"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c878eac71b82c5c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_root = '/home/suqi/dataset/Pub_Fin_Syn_Union_Clean'\n",
    "curr_root = '/home/suqi/dataset/temp/Pub_Fin_Syn_split'\n",
    "\n",
    "val_list = [name.split('.xml')[0] for name in sorted(os.listdir(os.path.join(data_root, 'val')))]\n",
    "pub_list = [name for name in val_list if ('CELL' not in name) and ('COL' not in name)]\n",
    "syn_list = list(set(val_list) - set(pub_list))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "170cd26b16a8ff4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(curr_root, 'pubset', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(curr_root, 'pubset', 'val'), exist_ok=True)\n",
    "os.makedirs(os.path.join(curr_root, 'synset', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(curr_root, 'synset', 'val'), exist_ok=True)\n",
    "\n",
    "for name in pub_list:\n",
    "    os.link(os.path.join(data_root, 'images', name + '.jpg'),\n",
    "            os.path.join(curr_root, 'pubset', 'images', name + '.jpg'))\n",
    "    os.link(os.path.join(data_root, 'val', name + '.xml'), os.path.join(curr_root, 'pubset', 'val', name + '.xml'))\n",
    "    with open(os.path.join(curr_root, 'pubset', 'val_filelist.txt'), 'a') as f:\n",
    "        f.write(f'val/{name}.xml\\n')\n",
    "\n",
    "for name in syn_list:\n",
    "    os.link(os.path.join(data_root, 'images', name + '.jpg'),\n",
    "            os.path.join(curr_root, 'synset', 'images', name + '.jpg'))\n",
    "    os.link(os.path.join(data_root, 'val', name + '.xml'), os.path.join(curr_root, 'synset', 'val', name + '.xml'))\n",
    "    with open(os.path.join(curr_root, 'synset', 'val_filelist.txt'), 'a') as f:\n",
    "        f.write(f'val/{name}.xml\\n')\n",
    "\n",
    "# 40057 43155\n",
    "# 45251 45251"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b29fd5b044a1e667"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 测试模型计算量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce1f6e478924c790"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "args.config_file = \"../structure_config_res34_large.json\"\n",
    "args.data_type = None\n",
    "args.backbone = \"resnet34\"\n",
    "# args.model_load_path = \"/home/suqi/model/TATR/finetune/20231016093942/model_1.pth\"\n",
    "args.device = \"cuda\"\n",
    "\n",
    "cmd_args = args.__dict__\n",
    "config_args = json.load(open(cmd_args['config_file'], 'rb'))\n",
    "for key, value in cmd_args.items():\n",
    "    if not key in config_args or not value is None:\n",
    "        config_args[key] = value\n",
    "# config_args.update(cmd_args)\n",
    "args = type('Args', (object,), config_args)\n",
    "\n",
    "os.makedirs(args.debug_save_dir, exist_ok=True)\n",
    "\n",
    "# define and load model\n",
    "device = torch.device(args.device)\n",
    "model, _, _ = get_model(args, device)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a19a3b026062dcc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "from detr.util.misc import nested_tensor_from_tensor_list\n",
    "\n",
    "x = torch.randn(size=(1, 3, 1024, 1024), device=args.device)\n",
    "\n",
    "# backbone\n",
    "if isinstance(x, (list, torch.Tensor)):\n",
    "    x = nested_tensor_from_tensor_list(x)\n",
    "\n",
    "# transformer\n",
    "features, pos = model.backbone(x)\n",
    "\n",
    "src, mask = features[-1].decompose()\n",
    "assert mask is not None\n",
    "src = model.input_proj(src)\n",
    "\n",
    "# encoder, decoder\n",
    "query_embed = model.query_embed.weight\n",
    "pos_embed = pos[-1]\n",
    "bs, c, h, w = src.shape\n",
    "src = src.flatten(2).permute(2, 0, 1)\n",
    "pos_embed = pos_embed.flatten(2).permute(2, 0, 1)\n",
    "query_embed = query_embed.unsqueeze(1).repeat(1, bs, 1)\n",
    "mask = mask.flatten(1)\n",
    "\n",
    "tgt = torch.zeros_like(query_embed)\n",
    "memory = model.transformer.encoder(src, src_key_padding_mask=mask, pos=pos_embed)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # flops, params = profile(model, (x,))\n",
    "    # flops, params = profile(model.backbone, (x,))\n",
    "    # flops, params = profile(model.transformer, (src, mask, model.query_embed.weight, pos[-1]))\n",
    "    flops, params = profile(model.transformer.encoder, (src, None, mask, pos_embed))\n",
    "    # flops, params = profile(model.transformer.decoder, (tgt, memory, None, None, None, mask, pos_embed, query_embed))\n",
    "    print('FLOPs = ' + str(flops / 1000 ** 3) + 'G')\n",
    "    print('Params = ' + str(params / 1000 ** 2) + 'M')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36568dbf26e17622"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46f66dff784fb15b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 测试Swin Transformer Backbone"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "917ddfa46a001de0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tmd.resnet50(pretrained=True).cuda().eval()\n",
    "x = torch.randn(size=(1, 3, 1024, 1024)).cuda()\n",
    "# for name, parameter in model.named_parameters():\n",
    "#     print(name)\n",
    "    \n",
    "model = IntermediateLayerGetter(model, return_layers={'layer4': '0'})\n",
    "print(model(x)['0'].shape)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     flops, params = profile(model, (x,))\n",
    "#     print('FLOPs = ' + str(flops/1000**3) + 'G')\n",
    "#     print('Params = ' + str(params/1000**2) + 'M')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37e87d215a5baeed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "20ddbd59cb5ff47b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
